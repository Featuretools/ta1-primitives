#!/usr/bin/env python3.6
# From the structure of nist/ta1-pipeline-submission/ta1-pipeline.py
from d3m.primitives.sklearn_wrap import SKRandomForestRegressor
#from d3m.primitives.featuretools_ta1 import (DFS,
#                                            Encoder,
#                                            Imputer,
#                                            RFRegressorFeatureSelector)
from featuretools_ta1.dfs import DFS
from featuretools_ta1.encoder import Encoder
from featuretools_ta1.imputer import Imputer
from featuretools_ta1.rf_reg_selector import RFRegressorFeatureSelector
from d3m.container.dataset import D3MDatasetLoader
from d3m.metadata.problem import parse_problem_description
from d3m.metadata.base import ALL_ELEMENTS
import pandas as pd
import os
import json


with open("/Users/bschreck/FeatureLabs/d3m/FeatureLabs_MIT/ta1-pipeline-config.json", 'r') as input_file:
    json_config = json.load(input_file)
train_uri = 'file://{}/dataset_TRAIN/datasetDoc.json'.format(
        json_config['train_data'])
test_uri = 'file://{}/dataset_TEST/datasetDoc.json'.format(
        json_config['test_data'])
problem_uri = os.path.join(json_config['test_data'],
                           'problem_TEST/problemDoc.json')

train_ds = D3MDatasetLoader().load(dataset_uri=train_uri)
test_ds = D3MDatasetLoader().load(dataset_uri=test_uri)
problem = parse_problem_description(problem_uri)

n_resources = train_ds.metadata.query(())['dimension']['length']
res_stypes = {str(res_id): train_ds.metadata.query((str(res_id),))['semantic_types']
              for res_id in range(n_resources)}
EntryPoint = 'https://metadata.datadrivendiscovery.org/types/DatasetEntryPoint'
Target = 'https://metadata.datadrivendiscovery.org/types/Target'
learning_data_res_id = [res_id for res_id, stypes
                        in res_stypes.items()
                        if EntryPoint in stypes][0]
target_index = problem['inputs'][0]['targets'][0]['column_index']
target_col_metadata = dict(train_ds.metadata.query((learning_data_res_id, ALL_ELEMENTS, target_index)))
target_name = target_col_metadata['name']
semantic_types = list(target_col_metadata['semantic_types']) + [Target]
target_col_metadata['semantic_types'] = semantic_types
new_metadata = train_ds.metadata.update((learning_data_res_id, ALL_ELEMENTS, target_index), target_col_metadata)
new_test_metadata = test_ds.metadata.update((learning_data_res_id, ALL_ELEMENTS, target_index), target_col_metadata)
train_ds.metadata = new_metadata
test_ds.metadata = new_test_metadata

metadata = DFS.metadata.query()['primitive_code']
hyperparams_class = metadata['class_type_arguments']['Hyperparams']
hp = hyperparams_class(hyperparams_class.defaults(),
                       normalize_categoricals_if_single_table=False)
dfs = DFS(hyperparams=hp)
dfs.set_training_data(inputs=train_ds)
dfs.fit()

train_feature_matrix = dfs.produce(inputs=train_ds).value

enc_metadata = Encoder.metadata.query()['primitive_code']
enc_hyperparams_class = enc_metadata['class_type_arguments']['Hyperparams']
encoder_hp = enc_hyperparams_class(enc_hyperparams_class.defaults())
encoder = Encoder(hyperparams=encoder_hp)
train_feature_matrix_encoded = encoder.produce(inputs=train_feature_matrix).value

dfs.set_training_data(inputs=train_feature_matrix_encoded)
test_feature_matrix_encoded = dfs.produce(inputs=test_ds).value


train_targets = train_ds[learning_data_res_id].iloc[:, target_index]

feature_names = train_feature_matrix.columns

metadata = Imputer.metadata.query()['primitive_code']
ImputerHP = metadata['class_type_arguments']['Hyperparams']
imputer = Imputer(hyperparams=ImputerHP.defaults())
train_feature_matrix = imputer.produce(inputs=train_feature_matrix_encoded).value
test_feature_matrix = imputer.produce(inputs=test_feature_matrix_encoded).value

metadata = SKRandomForestRegressor.metadata.query()['primitive_code']
RFHyperparams = metadata['class_type_arguments']['Hyperparams']

metadata = RFRegressorFeatureSelector.metadata.query()['primitive_code']
SelectorHP = metadata['class_type_arguments']['Hyperparams']
selector_hp = SelectorHP(SelectorHP.defaults(), select_n_features=100)
selector = RFRegressorFeatureSelector(hyperparams=selector_hp)
selector.set_training_data(inputs=train_feature_matrix, outputs=train_targets)
selector.fit()
train_feature_matrix = selector.produce(inputs=train_feature_matrix).value
test_feature_matrix = selector.produce(inputs=test_feature_matrix).value

hp = RFHyperparams(RFHyperparams.defaults(),
                   n_estimators=200,
                   n_jobs=-1,
                   max_features='sqrt')
rf = SKRandomForestRegressor(hyperparams=hp)

rf.set_training_data(inputs=train_feature_matrix, outputs=train_targets)
rf.fit()
predicted_targets = rf.produce(inputs=test_feature_matrix).value

test_index = test_feature_matrix.index.get_level_values('d3mIndex')
predicted_targets = pd.DataFrame(predicted_targets,
                                 columns=[target_name],
                                 index=test_index)
# Outputs the predicted targets in the location specified in the JSON
# configuration file
predictions_file = problem['outputs']['predictions_file']
output_file_path = os.path.join(json_config['output_folder'], predictions_file)
with open(output_file_path, 'w') as output_file:
    predicted_targets.to_csv(output_file)
